{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from torch.utils.data import DataLoader, Dataset, random_split\n",
    "from lib.checkpoint import load_checkpoint, save_checkpoint\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "LSTM_NEUROES = 13*13*13\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EarlyStopping:\n",
    "    def __init__(self, patience=5, min_delta=0):\n",
    "        self.patience = patience\n",
    "        self.min_delta = min_delta\n",
    "        self.best_loss = None\n",
    "        self.counter = 0\n",
    "\n",
    "    def __call__(self, val_loss):\n",
    "        if self.best_loss is None:\n",
    "            self.best_loss = val_loss\n",
    "            return False\n",
    "\n",
    "        if val_loss < self.best_loss - self.min_delta:\n",
    "            self.best_loss = val_loss\n",
    "            self.counter = 0\n",
    "            return False\n",
    "        else:\n",
    "            self.counter += 1\n",
    "            if self.counter >= self.patience:\n",
    "                return True\n",
    "            return False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class LSTM(nn.Module):\n",
    "    def __init__(self, input_size=LSTM_NEUROES, hidden_size=128, num_layers=2, output_size=LSTM_NEUROES):\n",
    "        super(LSTM, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_size, output_size)\n",
    "        self.input_fc = nn.Linear(input_size + output_size, input_size)  # 映射到 input_size\n",
    "\n",
    "    def forward(self, input_t, prev_output, h_0, c_0):\n",
    "        if prev_output is not None:\n",
    "            input_t = torch.cat((input_t, prev_output), dim=1)\n",
    "            input_t = self.input_fc(input_t)  # 映射到原始input_size\n",
    "\n",
    "        input_t = input_t.unsqueeze(1)  # 调整形状为 (batch_size, seq_len, input_size)\n",
    "        out, (h_0, c_0) = self.lstm(input_t, (h_0, c_0))\n",
    "        out = self.fc(out[:, -1, :])\n",
    "        return out, h_0, c_0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 16, 8, 8, 8])\n",
      "torch.Size([1, 12, 23, 23, 23])\n",
      "torch.Size([1, 8, 83, 83, 83])\n",
      "torch.Size([1, 4, 323, 323, 323])\n",
      "torch.Size([1, 4, 32, 32, 32])\n"
     ]
    }
   ],
   "source": [
    "class CTNN3DDecoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CTNN3DDecoder, self).__init__()\n",
    "        self.fc = nn.Linear(LSTM_NEUROES, 8*8*8*16)\n",
    "        \n",
    "        self.cov1 = nn.ConvTranspose3d(in_channels = 16, out_channels = 14,\n",
    "                                kernel_size = 3, stride = 2, padding = 2)\n",
    "        self.cov2 = nn.ConvTranspose3d(in_channels = 14, out_channels = 12,\n",
    "                                kernel_size = 3, stride = 2, padding = 2)\n",
    "        self.relu1 = nn.ReLU()\n",
    "        \n",
    "        self.cov3 = nn.ConvTranspose3d(in_channels = 12, out_channels = 10,\n",
    "                                kernel_size = 3, stride = 2, padding = 2)\n",
    "        self.cov4 = nn.ConvTranspose3d(in_channels = 10, out_channels = 8,\n",
    "                                kernel_size = 3, stride = 2, padding = 2)\n",
    "        self.relu2 = nn.ReLU()\n",
    "                \n",
    "        self.cov5 = nn.ConvTranspose3d(in_channels = 8, out_channels = 6,\n",
    "                                kernel_size = 3, stride = 2, padding = 2)\n",
    "        self.cov6 = nn.ConvTranspose3d(in_channels = 6, out_channels = 4,\n",
    "                                kernel_size = 3, stride = 2, padding = 2)\n",
    "        self.relu3 = nn.ReLU()\n",
    "        self.upsample = nn.Upsample(size=(32, 32, 32), mode='nearest')        \n",
    "        \n",
    "        # self.cov4 = nn.Conv3d(in_channels = 40, out_channel = 1, )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = self.fc(x)\n",
    "        out = out.view(1, 16, 8, 8, 8)\n",
    "        print(out.shape)\n",
    "        \n",
    "        out = self.cov1(out)\n",
    "        out = self.cov2(out)\n",
    "        out = self.relu1(out)\n",
    "        print(out.shape)\n",
    "\n",
    "        out = self.cov3(out)\n",
    "        out = self.cov4(out)\n",
    "        out = self.relu2(out)\n",
    "        print(out.shape)\n",
    "        \n",
    "        out = self.cov5(out)\n",
    "        out = self.cov6(out)\n",
    "        out = self.relu3(out)\n",
    "        print(out.shape)\n",
    "        out = self.upsample(out)\n",
    "        print(out.shape)\n",
    "        \n",
    "model = CTNN3DDecoder()\n",
    "test = torch.randn(LSTM_NEUROES)\n",
    "model(test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTMDecoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(LSTMDecoder, self).__init__()\n",
    "        self.lstm = LSTM()\n",
    "        self.decoder = CTNN3DDecoder()\n",
    "        \n",
    "    def forward(self, x, prev_output, h_0, c_0):\n",
    "        out, h_0, c_0 = self.lstm(x, prev_output, h_0, c_0)\n",
    "        out = self.decoder(out)\n",
    "        return out, h_0, c_0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class dataset(Dataset):\n",
    "    def __init__(self, datas, voxel):\n",
    "        self.datas = datas\n",
    "        self.voxel = voxel\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.datas)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return self.datas[index], self.voxel[index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_subdata(epoch, datas, model, criterion, optimizer, device):\n",
    "    data_len = len(datas)\n",
    "    train_data, val_data = random_split(datas, [int(data_len*0.8), data_len-int(data_len*0.8)])\n",
    "    print(\"Epoch:{} Train Size:{} Val Size:{}\".format(epoch, len(train_data), len(val_data)))\n",
    "    \n",
    "    train_loader = DataLoader(train_data, batch_size=1, shuffle=True)\n",
    "    val_loader = DataLoader(val_data, batch_size=1, shuffle=True)\n",
    "    train_logs = []\n",
    "    val_logs = []\n",
    "    # move data and model to device\n",
    "    model.to(device)\n",
    "    val_data = val_data.to(device)\n",
    "    train_data = train_data.to(device)\n",
    "    criterion.to(device)\n",
    "    \n",
    "    start= time.time()\n",
    "    model.train()\n",
    "    for inputs, targets in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        batch_size = inputs.size(0)\n",
    "        h_0 = torch.zeros(model.num_layers, batch_size, model.hidden_size).to(inputs.device)\n",
    "        c_0 = torch.zeros(model.num_layers, batch_size, model.hidden_size).to(inputs.device)\n",
    "        prev_output = None\n",
    "\n",
    "        for t in range(seq_len):\n",
    "            input_t = inputs[:, t, :]\n",
    "            output, h_0, c_0 = model(input_t, prev_output, h_0, c_0)\n",
    "            prev_output = output\n",
    "\n",
    "        loss = criterion(output, targets)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_logs.append(loss.item())\n",
    "        \n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for inputs, targets in val_loader:\n",
    "            batch_size = inputs.size(0)\n",
    "            h_0 = torch.zeros(model.num_layers, batch_size, model.hidden_size).to(inputs.device)\n",
    "            c_0 = torch.zeros(model.num_layers, batch_size, model.hidden_size).to(inputs.device)\n",
    "            prev_output = None\n",
    "\n",
    "            for t in range(seq_len):\n",
    "                input_t = inputs[:, t, :]\n",
    "                output, h_0, c_0 = model(input_t, prev_output, h_0, c_0)\n",
    "                prev_output = output\n",
    "\n",
    "            loss = criterion(output, targets)\n",
    "            val_logs.append(loss.item())\n",
    "    end = time.time()\n",
    "    \n",
    "    print(\"Epoch:{} Sub Train Time:{:.2f} Train Loss:{:.4f} Val Loss:{:.4f}\".format(epoch, end-start, sum(train_logs)/len(train_logs), sum(val_logs)/len(val_logs)))\n",
    "    return sum(train_logs)/len(train_logs), sum(val_logs)/len(val_logs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_training(file_path, device, checkpoint_path):\n",
    "    model = LSTMDecoder()\n",
    "    criterion = nn.MSELoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.0001)\n",
    "    early_stopping = EarlyStopping(patience=5, min_delta=0.0001)\n",
    "    epoch_loss = []\n",
    "    num_epochs = 20\n",
    "    \n",
    "    start_epoch, epoch_losses, last_file, train_loss, val_loss = load_checkpoint(checkpoint_path, model, optimizer, device)\n",
    "\n",
    "\n",
    "\n",
    "    model.train()\n",
    "    for epoch in range(num_epochs):\n",
    "        start = time.time()\n",
    "        cnt = 0\n",
    "        train_loss = []\n",
    "        val_loss = []\n",
    "        datas = []\n",
    "        resume = (last_file is not None)\n",
    "        skip_cnt = 0\n",
    "        for root, dirs, files in os.walk(file_path):\n",
    "            start_io = time.time()\n",
    "            for file in files:\n",
    "                if resume:\n",
    "                    if last_file == os.path.join(root, file):\n",
    "                        print('Resuming from {}, Skip {} Files'.format(last_file, skip_cnt))\n",
    "                        resume = False\n",
    "                    skip_cnt += 1\n",
    "                    continue\n",
    "                \n",
    "                file_name = os.path.join(root, file)\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "forward() missing 1 required positional argument: 'c_0'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_399574/3177411137.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;31m# 第一次输入\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0minput_1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mLSTM_NEUROES\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# (batch_size, seq_len, input_size)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh_n\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mc_n\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh_0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mc_0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"第一次输出:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/main/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1192\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1195\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1196\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: forward() missing 1 required positional argument: 'c_0'"
     ]
    }
   ],
   "source": [
    "# 初始化模型\n",
    "model = LSTM()\n",
    "batch_size = 1\n",
    "\n",
    "# 初始化隐藏层状态\n",
    "h_0 = torch.zeros(model.num_layers, batch_size, model.hidden_size)\n",
    "c_0 = torch.zeros(model.num_layers, batch_size, model.hidden_size)\n",
    "\n",
    "# 第一次输入\n",
    "input_1 = torch.randn(batch_size, 1, LSTM_NEUROES)  # (batch_size, seq_len, input_size)\n",
    "output, h_n, c_n = model(input_1, h_0, c_0)\n",
    "print(\"第一次输出:\", output)\n",
    "\n",
    "# 第二次输入，使用第一次的输出作为一部分输入\n",
    "input_2 = torch.randn(batch_size, 1, LSTM_NEUROES)  # 另外的输入\n",
    "new_input = torch.cat((input_2, output.unsqueeze(1)), dim=2)  # 合并输出作为输入的一部分\n",
    "new_input = model.input_fc(new_input)  # 映射到原始input_size\n",
    "\n",
    "output, h_n, c_n = model(new_input, h_n, c_n)\n",
    "print(\"第二次输出:\", output)\n",
    "\n",
    "# 多次迭代输入进行修正\n",
    "num_iterations = 5\n",
    "for i in range(num_iterations):\n",
    "    input_next = torch.randn(batch_size, 1, LSTM_NEUROES)  # 另外的输入\n",
    "    new_input = torch.cat((input_next, output.unsqueeze(1)), dim=2)  # 合并输出作为输入的一部分\n",
    "    new_input = model.input_fc(new_input)  # 映射到原始input_size\n",
    "\n",
    "    output, h_n, c_n = model(new_input, h_n, c_n)\n",
    "    print(f\"第{i+3}次输出:\", output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "main",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
