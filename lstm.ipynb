{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device:  cuda\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAksAAAGwCAYAAAC5ACFFAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjkuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/TGe4hAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAyn0lEQVR4nO3deXxU1f3/8fckIRthEgiQIRpAFE3AABZMCPZRaIkmrqyFX4oimkqpgFIohQgCQi0KosGValWkFUWoWqqIYkBFiCxBLMiitaxCErYksiUhOb8/+DJ1SjiQMGEy8Ho+HvdB5txz7/2ck9R5986ZGYcxxggAAABVCvB1AQAAAHUZYQkAAMCCsAQAAGBBWAIAALAgLAEAAFgQlgAAACwISwAAABZBvi7gYlBZWak9e/aoQYMGcjgcvi4HAACcA2OMfvjhB8XGxiog4Mz3jwhLXrBnzx7FxcX5ugwAAFADu3bt0uWXX37G/YQlL2jQoIGkk5PtdDp9XA0AADgXJSUliouLcz+PnwlhyQtOvfTmdDoJSwAA+JmzLaFhgTcAAIAFYQkAAMCCsAQAAGDBmiUAAH6koqJC5eXlvi4DXlCvXj0FBgae93kISwAA6ORn7uTn56uoqMjXpcCLoqKi5HK5zutzEAlLAABI7qDUtGlThYeH8yHDfs4Yo6NHj6qwsFCS1KxZsxqfi7AEALjkVVRUuINSdHS0r8uBl4SFhUmSCgsL1bRp0xq/JMcCbwDAJe/UGqXw8HAfVwJvO/U7PZ91aIQlAAD+Dy+9XXy88TslLAEAAFgQlgAAACwISwAAwEPLli2VnZ3t6zLqDMISAAB+yuFwWLdJkybV6Lxr1qzR4MGDz6u2bt26acSIEed1jrqCjw4AAMBP7d271/3zvHnzNGHCBG3dutXdFhER4f7ZGKOKigoFBZ39qb9JkybeLdTPcWcJAIAqGGN0tOyETzZjzDnV6HK53FtkZKQcDof78ZYtW9SgQQN98MEH6tixo0JCQvT555/ru+++U48ePRQTE6OIiAhdf/31+vjjjz3O+78vwzkcDv3lL39Rr169FB4ertatW2vhwoXnNb9///vf1bZtW4WEhKhly5aaMWOGx/7nn39erVu3VmhoqGJiYtS3b1/3vgULFigxMVFhYWGKjo5Wamqqjhw5cl712HBnCQCAKhwrr1CbCR/65NqbJqcpPNg7T9Fjx47VE088oVatWqlhw4batWuXbrnlFj366KMKCQnRnDlzdPvtt2vr1q1q3rz5Gc/zyCOPaNq0aZo+fbqeeeYZDRgwQDt27FCjRo2qXVNeXp769eunSZMmqX///lq5cqXuv/9+RUdHa9CgQVq7dq0eeOAB/fWvf1WXLl108OBBLV++XNLJu2kZGRmaNm2aevXqpR9++EHLly8/54BZE4QlAAAuYpMnT9aNN97oftyoUSO1b9/e/XjKlCl65513tHDhQg0bNuyM5xk0aJAyMjIkSX/605/09NNPa/Xq1UpPT692TU8++aS6d++uhx9+WJJ09dVXa9OmTZo+fboGDRqknTt3qn79+rrtttvUoEEDtWjRQtddd52kk2HpxIkT6t27t1q0aCFJSkxMrHYN1UFYAgCgCmH1ArVpcprPru0tnTp18nh8+PBhTZo0Se+//747eBw7dkw7d+60nqddu3bun+vXry+n0+n+3rXq2rx5s3r06OHRdsMNNyg7O1sVFRW68cYb1aJFC7Vq1Urp6elKT093vwTYvn17de/eXYmJiUpLS9NNN92kvn37qmHDhjWq5VywZgkAgCo4HA6FBwf5ZPPmJ4nXr1/f4/Hvf/97vfPOO/rTn/6k5cuXa/369UpMTFRZWZn1PPXq1TttfiorK71W5481aNBA69at0xtvvKFmzZppwoQJat++vYqKihQYGKglS5bogw8+UJs2bfTMM8/ommuu0bZt22qlFomwBADAJWXFihUaNGiQevXqpcTERLlcLm3fvv2C1pCQkKAVK1acVtfVV1/t/rLboKAgpaamatq0afrXv/6l7du3a+nSpZJOBrUbbrhBjzzyiL788ksFBwfrnXfeqbV6eRkOAIBLSOvWrfX222/r9ttvl8Ph0MMPP1xrd4j27dun9evXe7Q1a9ZMo0aN0vXXX68pU6aof//+ys3N1bPPPqvnn39ekvTee+/pP//5j372s5+pYcOGWrRokSorK3XNNddo1apVysnJ0U033aSmTZtq1apV2rdvnxISEmplDBJhCQCAS8qTTz6pe++9V126dFHjxo01ZswYlZSU1Mq15s6dq7lz53q0TZkyRePHj9dbb72lCRMmaMqUKWrWrJkmT56sQYMGSZKioqL09ttva9KkSTp+/Lhat26tN954Q23bttXmzZv12WefKTs7WyUlJWrRooVmzJihm2++uVbGIEkOU5vvtbtElJSUKDIyUsXFxXI6nb4uBwBQTcePH9e2bdt0xRVXKDQ01NflwItsv9tzff5mzRIAAIAFYQkAAMCCsAQAAGBBWAIAALAgLAEAAFgQlgAAACwISwAAABaEJQAAAAvCEgAAl7hu3bppxIgRvi6jziIsAQDgp26//Xalp6dXuW/58uVyOBz617/+dd7XmT17tqKios77PP6KsAQAgJ/KzMzUkiVLtHv37tP2vfrqq+rUqZPatWvng8ouLoQlAAD81G233aYmTZpo9uzZHu2HDx/W/PnzlZmZqQMHDigjI0OXXXaZwsPDlZiYqDfeeMOrdezcuVM9evRQRESEnE6n+vXrp4KCAvf+r776Sj//+c/VoEEDOZ1OdezYUWvXrpUk7dixQ7fffrsaNmyo+vXrq23btlq0aJFX6ztfQb4uAACAOskYqfyob65dL1xyOM7aLSgoSAMHDtTs2bM1btw4Of7vmPnz56uiokIZGRk6fPiwOnbsqDFjxsjpdOr999/XXXfdpSuvvFJJSUnnXWplZaU7KH366ac6ceKEhg4dqv79++uTTz6RJA0YMEDXXXedXnjhBQUGBmr9+vWqV6+eJGno0KEqKyvTZ599pvr162vTpk2KiIg477q8ibAEAEBVyo9Kf4r1zbUf2iMF1z+nrvfee6+mT5+uTz/9VN26dZN08iW4Pn36KDIyUpGRkfr973/v7j98+HB9+OGHeuutt7wSlnJycrRhwwZt27ZNcXFxkqQ5c+aobdu2WrNmja6//nrt3LlTo0ePVnx8vCSpdevW7uN37typPn36KDExUZLUqlWr867J23gZDgAAPxYfH68uXbrolVdekST9+9//1vLly5WZmSlJqqio0JQpU5SYmKhGjRopIiJCH374oXbu3OmV62/evFlxcXHuoCRJbdq0UVRUlDZv3ixJGjlypH79618rNTVVjz32mL777jt33wceeEB//OMfdcMNN2jixIleWZDubdxZAgCgKvXCT97h8dW1qyEzM1PDhw/Xc889p1dffVVXXnmlunbtKkmaPn26Zs6cqezsbCUmJqp+/foaMWKEysrKaqPyKk2aNEm/+tWv9P777+uDDz7QxIkT9eabb6pXr1769a9/rbS0NL3//vv66KOPNHXqVM2YMUPDhw+/YPWdDXeWAACoisNx8qUwX2znsF7px/r166eAgADNnTtXc+bM0b333utev7RixQr16NFDd955p9q3b69WrVrpm2++8do0JSQkaNeuXdq1a5e7bdOmTSoqKlKbNm3cbVdffbV+97vf6aOPPlLv3r316quvuvfFxcVpyJAhevvttzVq1Ci99NJLXqvPG7izBACAn4uIiFD//v2VlZWlkpISDRo0yL2vdevWWrBggVauXKmGDRvqySefVEFBgUeQORcVFRVav369R1tISIhSU1OVmJioAQMGKDs7WydOnND999+vrl27qlOnTjp27JhGjx6tvn376oorrtDu3bu1Zs0a9enTR5I0YsQI3Xzzzbr66qt16NAhLVu2TAkJCec7JV5FWAIA4CKQmZmpl19+WbfccotiY/+7MH38+PH6z3/+o7S0NIWHh2vw4MHq2bOniouLq3X+w4cP67rrrvNou/LKK/Xvf/9b//jHPzR8+HD97Gc/U0BAgNLT0/XMM89IkgIDA3XgwAENHDhQBQUFaty4sXr37q1HHnlE0skQNnToUO3evVtOp1Pp6el66qmnznM2vMthjDG+LsLflZSUKDIyUsXFxXI6nb4uBwBQTcePH9e2bdt0xRVXKDQ01NflwItsv9tzff5mzRIAAICF34Wl5557Ti1btlRoaKiSk5O1evVqa//58+crPj5eoaGhSkxMtH4q6JAhQ+RwOJSdne3lqgEAgL/yq7A0b948jRw5UhMnTtS6devUvn17paWlqbCwsMr+K1euVEZGhjIzM/Xll1+qZ8+e6tmzpzZu3Hha33feeUdffPGFx+u8AAAAfhWWnnzySd13332655571KZNG82aNUvh4eHuD+L6XzNnzlR6erpGjx6thIQETZkyRT/5yU/07LPPevT7/vvvNXz4cL3++uvuj18HAACQ/CgslZWVKS8vT6mpqe62gIAApaamKjc3t8pjcnNzPfpLUlpamkf/yspK3XXXXRo9erTatm17TrWUlpaqpKTEYwMA+D/e83Tx8cbv1G/C0v79+1VRUaGYmBiP9piYGOXn51d5TH5+/ln7P/744woKCtIDDzxwzrVMnTrV/X07kZGRHh/xDgDwP6deVTh61EdfnItac+p3ej6vHF3Sn7OUl5enmTNnat26de5POj0XWVlZGjlypPtxSUkJgQkA/FhgYKCioqLca2DDw8Or9byAuscYo6NHj6qwsFBRUVEKDAys8bn8Jiw1btxYgYGBKigo8GgvKCiQy+Wq8hiXy2Xtv3z5chUWFqp58+bu/RUVFRo1apSys7O1ffv2Ks8bEhKikJCQ8xgNAKCuOfXccKY3DcE/RUVFnTEnnCu/CUvBwcHq2LGjcnJy1LNnT0kn1xvl5ORo2LBhVR6TkpKinJwcjRgxwt22ZMkSpaSkSJLuuuuuKtc03XXXXbrnnntqZRwAgLrJ4XCoWbNmatq0qcrLy31dDrygXr1653VH6RS/CUuSNHLkSN19993q1KmTkpKSlJ2drSNHjriDzcCBA3XZZZdp6tSpkqQHH3xQXbt21YwZM3TrrbfqzTff1Nq1a/Xiiy9KkqKjoxUdHe1xjXr16snlcumaa665sIMDANQJgYGBXnmCxcXDr8JS//79tW/fPk2YMEH5+fnq0KGDFi9e7F7EvXPnTgUE/HfNepcuXTR37lyNHz9eDz30kFq3bq13331X1157ra+GAAAA/AzfDecFfDccAAD+h++GAwAA8ALCEgAAgAVhCQAAwIKwBAAAYEFYAgAAsCAsAQAAWBCWAAAALAhLAAAAFoQlAAAAC8ISAACABWEJAADAgrAEAABgQVgCAACwICwBAABYEJYAAAAsCEsAAAAWhCUAAAALwhIAAIAFYQkAAMCCsAQAAGBBWAIAALAgLAEAAFgQlgAAACwISwAAABaEJQAAAAvCEgAAgAVhCQAAwIKwBAAAYEFYAgAAsCAsAQAAWBCWAAAALAhLAAAAFoQlAAAAC8ISAACABWEJAADAgrAEAABgQVgCAACwICwBAABYEJYAAAAsCEsAAAAWhCUAAAALwhIAAIAFYQkAAMCCsAQAAGBBWAIAALAgLAEAAFgQlgAAACwISwAAABaEJQAAAAvCEgAAgAVhCQAAwIKwBAAAYEFYAgAAsCAsAQAAWBCWAAAALAhLAAAAFn4Xlp577jm1bNlSoaGhSk5O1urVq63958+fr/j4eIWGhioxMVGLFi1y7ysvL9eYMWOUmJio+vXrKzY2VgMHDtSePXtqexgAAMBP+FVYmjdvnkaOHKmJEydq3bp1at++vdLS0lRYWFhl/5UrVyojI0OZmZn68ssv1bNnT/Xs2VMbN26UJB09elTr1q3Tww8/rHXr1untt9/W1q1bdccdd1zIYQEAgDrMYYwxvi7iXCUnJ+v666/Xs88+K0mqrKxUXFychg8frrFjx57Wv3///jpy5Ijee+89d1vnzp3VoUMHzZo1q8prrFmzRklJSdqxY4eaN29+TnWVlJQoMjJSxcXFcjqdNRgZAAC40M71+dtv7iyVlZUpLy9Pqamp7raAgAClpqYqNze3ymNyc3M9+ktSWlraGftLUnFxsRwOh6Kios7Yp7S0VCUlJR4bAAC4OPlNWNq/f78qKioUExPj0R4TE6P8/Pwqj8nPz69W/+PHj2vMmDHKyMiwJsypU6cqMjLSvcXFxVVzNAAAwF/4TViqbeXl5erXr5+MMXrhhResfbOyslRcXOzedu3adYGqBAAAF1qQrws4V40bN1ZgYKAKCgo82gsKCuRyuao8xuVynVP/U0Fpx44dWrp06VnXHYWEhCgkJKQGowAAAP7Gb+4sBQcHq2PHjsrJyXG3VVZWKicnRykpKVUek5KS4tFfkpYsWeLR/1RQ+vbbb/Xxxx8rOjq6dgYAAAD8kt/cWZKkkSNH6u6771anTp2UlJSk7OxsHTlyRPfcc48kaeDAgbrssss0depUSdKDDz6orl27asaMGbr11lv15ptvau3atXrxxRclnQxKffv21bp16/Tee++poqLCvZ6pUaNGCg4O9s1AAQBAneFXYal///7at2+fJkyYoPz8fHXo0EGLFy92L+LeuXOnAgL+e7OsS5cumjt3rsaPH6+HHnpIrVu31rvvvqtrr71WkvT9999r4cKFkqQOHTp4XGvZsmXq1q3bBRkXAACou/zqc5bqKj5nCQAA/3PRfc4SAACALxCWAAAALAhLAAAAFoQlAAAAC8ISAACABWEJAADAgrAEAABgQVgCAACwICwBAABYEJYAAAAsCEsAAAAWhCUAAAALwhIAAIAFYQkAAMCCsAQAAGBBWAIAALAgLAEAAFgQlgAAACwISwAAABaEJQAAAAvCEgAAgAVhCQAAwIKwBAAAYEFYAgAAsCAsAQAAWBCWAAAALAhLAAAAFoQlAAAAC8ISAACABWEJAADAgrAEAABgQVgCAACwICwBAABYEJYAAAAsCEsAAAAWhCUAAAALwhIAAIAFYQkAAMCCsAQAAGBBWAIAALAgLAEAAFgQlgAAACwISwAAABaEJQAAAAvCEgAAgAVhCQAAwIKwBAAAYEFYAgAAsCAsAQAAWNQoLO3atUu7d+92P169erVGjBihF1980WuFAQAA1AU1Cku/+tWvtGzZMklSfn6+brzxRq1evVrjxo3T5MmTvVogAACAL9UoLG3cuFFJSUmSpLfeekvXXnutVq5cqddff12zZ8/2Zn0AAAA+VaOwVF5erpCQEEnSxx9/rDvuuEOSFB8fr71793qvOgAAAB+rUVhq27atZs2apeXLl2vJkiVKT0+XJO3Zs0fR0dFeLRAAAMCXahSWHn/8cf35z39Wt27dlJGRofbt20uSFi5c6H55DgAA4GLgMMaYmhxYUVGhkpISNWzY0N22fft2hYeHq2nTpl4r0B+UlJQoMjJSxcXFcjqdvi4HAACcg3N9/q7RnaVjx46ptLTUHZR27Nih7Oxsbd26tdaD0nPPPaeWLVsqNDRUycnJWr16tbX//PnzFR8fr9DQUCUmJmrRokUe+40xmjBhgpo1a6awsDClpqbq22+/rc0hAAAAP1KjsNSjRw/NmTNHklRUVKTk5GTNmDFDPXv21AsvvODVAn9s3rx5GjlypCZOnKh169apffv2SktLU2FhYZX9V65cqYyMDGVmZurLL79Uz5491bNnT23cuNHdZ9q0aXr66ac1a9YsrVq1SvXr11daWpqOHz9ea+MAAAB+xNRAdHS02bhxozHGmJdeesm0a9fOVFRUmLfeesvEx8fX5JTnJCkpyQwdOtT9uKKiwsTGxpqpU6dW2b9fv37m1ltv9WhLTk42v/nNb4wxxlRWVhqXy2WmT5/u3l9UVGRCQkLMG2+8cc51FRcXG0mmuLi4OsMBAAA+dK7P3zW6s3T06FE1aNBAkvTRRx+pd+/eCggIUOfOnbVjxw4vRrn/KisrU15enlJTU91tAQEBSk1NVW5ubpXH5ObmevSXpLS0NHf/bdu2KT8/36NPZGSkkpOTz3hOSSotLVVJSYnHBgAALk41CktXXXWV3n33Xe3atUsffvihbrrpJklSYWFhrS1w3r9/vyoqKhQTE+PRHhMTo/z8/CqPyc/Pt/Y/9W91zilJU6dOVWRkpHuLi4ur9ngAAIB/qFFYmjBhgn7/+9+rZcuWSkpKUkpKiqSTd5muu+46rxZYF2VlZam4uNi97dq1y9clAQCAWhJUk4P69u2rn/70p9q7d6/7M5YkqXv37urVq5fXivuxxo0bKzAwUAUFBR7tBQUFcrlcVR7jcrms/U/9W1BQoGbNmnn06dChwxlrCQkJcX+COQAAuLjV6M6SdDJoXHfdddqzZ492794tSUpKSlJ8fLzXivux4OBgdezYUTk5Oe62yspK5eTkuO9s/a+UlBSP/pK0ZMkSd/8rrrhCLpfLo09JSYlWrVp1xnMCAIBLS43CUmVlpSZPnqzIyEi1aNFCLVq0UFRUlKZMmaLKykpv1+g2cuRIvfTSS3rttde0efNm/fa3v9WRI0d0zz33SJIGDhyorKwsd/8HH3xQixcv1owZM7RlyxZNmjRJa9eu1bBhwyRJDodDI0aM0B//+EctXLhQGzZs0MCBAxUbG6uePXvW2jgAAID/qNHLcOPGjdPLL7+sxx57TDfccIMk6fPPP9ekSZN0/PhxPfroo14t8pT+/ftr3759mjBhgvLz89WhQwctXrzYvUB7586dCgj4b/7r0qWL5s6dq/Hjx+uhhx5S69at9e677+raa6919/nDH/6gI0eOaPDgwSoqKtJPf/pTLV68WKGhobUyBgAA4F9q9HUnsbGxmjVrlu644w6P9n/84x+6//779f3333utQH/A150AAOB/avXrTg4ePFjl2qT4+HgdPHiwJqcEAACok2oUltq3b69nn332tPZnn31W7dq1O++iAAAA6ooarVmaNm2abr31Vn388cfud43l5uZq165dp31RLQAAgD+r0Z2lrl276ptvvlGvXr1UVFSkoqIi9e7dW19//bX++te/ertGAAAAn6nRAu8z+eqrr/STn/xEFRUV3jqlX2CBNwAA/qdWF3gDAABcKghLAAAAFoQlAAAAi2q9G653797W/UVFRedTCwAAQJ1TrbAUGRl51v0DBw48r4IAAADqkmqFpVdffbW26gAAAKiTWLMEAABgQVgCAACwICwBAABYEJYAAAAsCEsAAAAWhCUAAAALwhIAAIAFYQkAAMCCsAQAAGBBWAIAALAgLAEAAFgQlgAAACwISwAAABaEJQAAAAvCEgAAgAVhCQAAwIKwBAAAYEFYAgAAsCAsAQAAWBCWAAAALAhLAAAAFoQlAAAAC8ISAACABWEJAADAgrAEAABgQVgCAACwICwBAABYEJYAAAAsCEsAAAAWhCUAAAALwhIAAIAFYQkAAMCCsAQAAGBBWAIAALAgLAEAAFgQlgAAACwISwAAABaEJQAAAAvCEgAAgAVhCQAAwIKwBAAAYEFYAgAAsCAsAQAAWBCWAAAALAhLAAAAFoQlAAAAC78JSwcPHtSAAQPkdDoVFRWlzMxMHT582HrM8ePHNXToUEVHRysiIkJ9+vRRQUGBe/9XX32ljIwMxcXFKSwsTAkJCZo5c2ZtDwUAAPgRvwlLAwYM0Ndff60lS5bovffe02effabBgwdbj/nd736nf/7zn5o/f74+/fRT7dmzR71793bvz8vLU9OmTfW3v/1NX3/9tcaNG6esrCw9++yztT0cAADgJxzGGOPrIs5m8+bNatOmjdasWaNOnTpJkhYvXqxbbrlFu3fvVmxs7GnHFBcXq0mTJpo7d6769u0rSdqyZYsSEhKUm5urzp07V3mtoUOHavPmzVq6dOkZ6yktLVVpaan7cUlJieLi4lRcXCyn03k+QwUAABdISUmJIiMjz/r87Rd3lnJzcxUVFeUOSpKUmpqqgIAArVq1qspj8vLyVF5ertTUVHdbfHy8mjdvrtzc3DNeq7i4WI0aNbLWM3XqVEVGRrq3uLi4ao4IAAD4C78IS/n5+WratKlHW1BQkBo1aqT8/PwzHhMcHKyoqCiP9piYmDMes3LlSs2bN++sL+9lZWWpuLjYve3atevcBwMAAPyKT8PS2LFj5XA4rNuWLVsuSC0bN25Ujx49NHHiRN10003WviEhIXI6nR4bAAC4OAX58uKjRo3SoEGDrH1atWoll8ulwsJCj/YTJ07o4MGDcrlcVR7ncrlUVlamoqIij7tLBQUFpx2zadMmde/eXYMHD9b48eNrNBYAAHBx8mlYatKkiZo0aXLWfikpKSoqKlJeXp46duwoSVq6dKkqKyuVnJxc5TEdO3ZUvXr1lJOToz59+kiStm7dqp07dyolJcXd7+uvv9YvfvEL3X333Xr00Ue9MCoAAHAx8Yt3w0nSzTffrIKCAs2aNUvl5eW655571KlTJ82dO1eS9P3336t79+6aM2eOkpKSJEm//e1vtWjRIs2ePVtOp1PDhw+XdHJtknTypbdf/OIXSktL0/Tp093XCgwMPKcQd8q5rqYHAAB1x7k+f/v0zlJ1vP766xo2bJi6d++ugIAA9enTR08//bR7f3l5ubZu3aqjR4+625566il339LSUqWlpen5559371+wYIH27dunv/3tb/rb3/7mbm/RooW2b99+QcYFAADqNr+5s1SXcWcJAAD/c1F9zhIAAICvEJYAAAAsCEsAAAAWhCUAAAALwhIAAIAFYQkAAMCCsAQAAGBBWAIAALAgLAEAAFgQlgAAACwISwAAABaEJQAAAAvCEgAAgAVhCQAAwIKwBAAAYEFYAgAAsCAsAQAAWBCWAAAALAhLAAAAFoQlAAAAC8ISAACABWEJAADAgrAEAABgQVgCAACwICwBAABYEJYAAAAsCEsAAAAWhCUAAAALwhIAAIAFYQkAAMCCsAQAAGBBWAIAALAgLAEAAFgQlgAAACwISwAAABaEJQAAAAvCEgAAgAVhCQAAwIKwBAAAYEFYAgAAsCAsAQAAWBCWAAAALAhLAAAAFoQlAAAAC8ISAACABWEJAADAgrAEAABgQVgCAACwICwBAABYEJYAAAAsCEsAAAAWhCUAAAALwhIAAIAFYQkAAMCCsAQAAGBBWAIAALDwm7B08OBBDRgwQE6nU1FRUcrMzNThw4etxxw/flxDhw5VdHS0IiIi1KdPHxUUFFTZ98CBA7r88svlcDhUVFRUCyMAAAD+yG/C0oABA/T1119ryZIleu+99/TZZ59p8ODB1mN+97vf6Z///Kfmz5+vTz/9VHv27FHv3r2r7JuZmal27drVRukAAMCPOYwxxtdFnM3mzZvVpk0brVmzRp06dZIkLV68WLfccot2796t2NjY044pLi5WkyZNNHfuXPXt21eStGXLFiUkJCg3N1edO3d2933hhRc0b948TZgwQd27d9ehQ4cUFRV1xnpKS0tVWlrqflxSUqK4uDgVFxfL6XR6adQAAKA2lZSUKDIy8qzP335xZyk3N1dRUVHuoCRJqampCggI0KpVq6o8Ji8vT+Xl5UpNTXW3xcfHq3nz5srNzXW3bdq0SZMnT9acOXMUEHBu0zF16lRFRka6t7i4uBqODAAA1HV+EZby8/PVtGlTj7agoCA1atRI+fn5ZzwmODj4tDtEMTEx7mNKS0uVkZGh6dOnq3nz5udcT1ZWloqLi93brl27qjcgAADgN3walsaOHSuHw2HdtmzZUmvXz8rKUkJCgu68885qHRcSEiKn0+mxAQCAi1OQLy8+atQoDRo0yNqnVatWcrlcKiws9Gg/ceKEDh48KJfLVeVxLpdLZWVlKioq8ri7VFBQ4D5m6dKl2rBhgxYsWCBJOrV8q3Hjxho3bpweeeSRGo4MAABcLHwalpo0aaImTZqctV9KSoqKioqUl5enjh07SjoZdCorK5WcnFzlMR07dlS9evWUk5OjPn36SJK2bt2qnTt3KiUlRZL097//XceOHXMfs2bNGt17771avny5rrzyyvMdHgAAuAj4NCydq4SEBKWnp+u+++7TrFmzVF5ermHDhun//b//534n3Pfff6/u3btrzpw5SkpKUmRkpDIzMzVy5Eg1atRITqdTw4cPV0pKivudcP8biPbv3+++nu3dcAAA4NLhF2FJkl5//XUNGzZM3bt3V0BAgPr06aOnn37avb+8vFxbt27V0aNH3W1PPfWUu29paanS0tL0/PPP+6J8AADgp/zic5bqunP9nAYAAFB3XFSfswQAAOArhCUAAAALwhIAAIAFYQkAAMCCsAQAAGBBWAIAALAgLAEAAFgQlgAAACwISwAAABaEJQAAAAvCEgAAgAVhCQAAwIKwBAAAYEFYAgAAsCAsAQAAWBCWAAAALAhLAAAAFoQlAAAAC8ISAACABWEJAADAgrAEAABgQVgCAACwICwBAABYEJYAAAAsCEsAAAAWhCUAAAALwhIAAIAFYQkAAMCCsAQAAGBBWAIAALAgLAEAAFgQlgAAACwISwAAABaEJQAAAAvCEgAAgAVhCQAAwIKwBAAAYEFYAgAAsCAsAQAAWBCWAAAALAhLAAAAFoQlAAAAiyBfF3AxMMZIkkpKSnxcCQAAOFennrdPPY+fCWHJC3744QdJUlxcnI8rAQAA1fXDDz8oMjLyjPsd5mxxCmdVWVmpPXv2qEGDBnI4HL4ux6dKSkoUFxenXbt2yel0+rqcixbzfOEw1xcG83xhMM+ejDH64YcfFBsbq4CAM69M4s6SFwQEBOjyyy/3dRl1itPp5H+IFwDzfOEw1xcG83xhMM//ZbujdAoLvAEAACwISwAAABaEJXhVSEiIJk6cqJCQEF+XclFjni8c5vrCYJ4vDOa5ZljgDQAAYMGdJQAAAAvCEgAAgAVhCQAAwIKwBAAAYEFYQrUdPHhQAwYMkNPpVFRUlDIzM3X48GHrMcePH9fQoUMVHR2tiIgI9enTRwUFBVX2PXDggC6//HI5HA4VFRXVwgj8Q23M81dffaWMjAzFxcUpLCxMCQkJmjlzZm0PpU557rnn1LJlS4WGhio5OVmrV6+29p8/f77i4+MVGhqqxMRELVq0yGO/MUYTJkxQs2bNFBYWptTUVH377be1OQS/4M15Li8v15gxY5SYmKj69esrNjZWAwcO1J49e2p7GHWet/+ef2zIkCFyOBzKzs72ctV+yADVlJ6ebtq3b2+++OILs3z5cnPVVVeZjIwM6zFDhgwxcXFxJicnx6xdu9Z07tzZdOnSpcq+PXr0MDfffLORZA4dOlQLI/APtTHPL7/8snnggQfMJ598Yr777jvz17/+1YSFhZlnnnmmtodTJ7z55psmODjYvPLKK+brr7829913n4mKijIFBQVV9l+xYoUJDAw006ZNM5s2bTLjx4839erVMxs2bHD3eeyxx0xkZKR59913zVdffWXuuOMOc8UVV5hjx45dqGHVOd6e56KiIpOammrmzZtntmzZYnJzc01SUpLp2LHjhRxWnVMbf8+nvP3226Z9+/YmNjbWPPXUU7U8krqPsIRq2bRpk5Fk1qxZ42774IMPjMPhMN9//32VxxQVFZl69eqZ+fPnu9s2b95sJJnc3FyPvs8//7zp2rWrycnJuaTDUm3P84/df//95uc//7n3iq/DkpKSzNChQ92PKyoqTGxsrJk6dWqV/fv162duvfVWj7bk5GTzm9/8xhhjTGVlpXG5XGb69Onu/UVFRSYkJMS88cYbtTAC/+Dtea7K6tWrjSSzY8cO7xTth2prnnfv3m0uu+wys3HjRtOiRQvCkjGGl+FQLbm5uYqKilKnTp3cbampqQoICNCqVauqPCYvL0/l5eVKTU11t8XHx6t58+bKzc11t23atEmTJ0/WnDlzrF9oeCmozXn+X8XFxWrUqJH3iq+jysrKlJeX5zE/AQEBSk1NPeP85ObmevSXpLS0NHf/bdu2KT8/36NPZGSkkpOTrXN+MauNea5KcXGxHA6HoqKivFK3v6mtea6srNRdd92l0aNHq23btrVTvB+6tJ+RUG35+flq2rSpR1tQUJAaNWqk/Pz8Mx4THBx82n/UYmJi3MeUlpYqIyND06dPV/PmzWuldn9SW/P8v1auXKl58+Zp8ODBXqm7Ltu/f78qKioUExPj0W6bn/z8fGv/U/9W55wXu9qY5/91/PhxjRkzRhkZGZfsl8HW1jw//vjjCgoK0gMPPOD9ov0YYQmSpLFjx8rhcFi3LVu21Nr1s7KylJCQoDvvvLPWrlEX+Hqef2zjxo3q0aOHJk6cqJtuuumCXBM4X+Xl5erXr5+MMXrhhRd8Xc5FJS8vTzNnztTs2bPlcDh8XU6dEuTrAlA3jBo1SoMGDbL2adWqlVwulwoLCz3aT5w4oYMHD8rlclV5nMvlUllZmYqKijzuehQUFLiPWbp0qTZs2KAFCxZIOvkOI0lq3Lixxo0bp0ceeaSGI6tbfD3Pp2zatEndu3fX4MGDNX78+BqNxd80btxYgYGBp70Ls6r5OcXlcln7n/q3oKBAzZo18+jToUMHL1bvP2pjnk85FZR27NihpUuXXrJ3laTamefly5ersLDQ4+5+RUWFRo0apezsbG3fvt27g/Anvl40Bf9yauHx2rVr3W0ffvjhOS08XrBggbtty5YtHguP//3vf5sNGza4t1deecVIMitXrjzjOzsuZrU1z8YYs3HjRtO0aVMzevTo2htAHZWUlGSGDRvmflxRUWEuu+wy64LY2267zaMtJSXltAXeTzzxhHt/cXExC7y9PM/GGFNWVmZ69uxp2rZtawoLC2uncD/j7Xnev3+/x3+HN2zYYGJjY82YMWPMli1bam8gfoCwhGpLT0831113nVm1apX5/PPPTevWrT3e0r57925zzTXXmFWrVrnbhgwZYpo3b26WLl1q1q5da1JSUkxKSsoZr7Fs2bJL+t1wxtTOPG/YsME0adLE3HnnnWbv3r3u7VJ58nnzzTdNSEiImT17ttm0aZMZPHiwiYqKMvn5+cYYY+666y4zduxYd/8VK1aYoKAg88QTT5jNmzebiRMnVvnRAVFRUeYf//iH+de//mV69OjBRwd4eZ7LysrMHXfcYS6//HKzfv16j7/d0tJSn4yxLqiNv+f/xbvhTiIsodoOHDhgMjIyTEREhHE6neaee+4xP/zwg3v/tm3bjCSzbNkyd9uxY8fM/fffbxo2bGjCw8NNr169zN69e894DcJS7czzxIkTjaTTthYtWlzAkfnWM888Y5o3b26Cg4NNUlKS+eKLL9z7unbtau6++26P/m+99Za5+uqrTXBwsGnbtq15//33PfZXVlaahx9+2MTExJiQkBDTvXt3s3Xr1gsxlDrNm/N86m+9qu3Hf/+XIm//Pf8vwtJJDmP+b3EIAAAATsO74QAAACwISwAAABaEJQAAAAvCEgAAgAVhCQAAwIKwBAAAYEFYAgAAsCAsAQAAWBCWAFyUPvnkEzkcDhUVFfm6lBrp1q2bRowY4esyAIiwBKCO2rdvn37729+qefPmCgkJkcvlUlpamlasWFGr1509e7YcDsdpW2hoaK1eF0DdFeTrAgCgKn369FFZWZlee+01tWrVSgUFBcrJydGBAwdq/dpOp1Nbt271aHM4HLV+XQB1E3eWANQ5RUVFWr58uR5//HH9/Oc/V4sWLZSUlKSsrCzdcccd2r59uxwOh9avX+9xjMPh0CeffOJxrhUrVqhdu3YKDQ1V586dtXHjxrNe3+FwyOVyeWwxMTHu/d26ddOwYcM0bNgwRUZGqnHjxnr44Yf146/aPHTokAYOHKiGDRsqPDxcN998s7799tvTauvWrZvCw8PVsGFDpaWl6dChQ+79lZWV+sMf/qBGjRrJ5XJp0qRJ1ZtIAF5BWAJQ50RERCgiIkLvvvuuSktLz+tco0eP1owZM7RmzRo1adJEt99+u8rLy8+7xtdee01BQUFavXq1Zs6cqSeffFJ/+ctf3PsHDRqktWvXauHChcrNzZUxRrfccov72uvXr1f37t3Vpk0b5ebm6vPPP9ftt9+uiooKj2vUr19fq1at0rRp0zR58mQtWbLkvGsHUE0GAOqgBQsWmIYNG5rQ0FDTpUsXk5WVZb766itjjDHbtm0zksyXX37p7n/o0CEjySxbtswYY8yyZcuMJPPmm2+6+xw4cMCEhYWZefPmnfG6r776qpFk6tev77Glp6e7+3Tt2tUkJCSYyspKd9uYMWNMQkKCMcaYb775xkgyK1ascO/fv3+/CQsLM2+99ZYxxpiMjAxzww03nLGOrl27mp/+9Kcebddff70ZM2bMGY8BUDu4swSgTurTp4/27NmjhQsXKj09XZ988ol+8pOfaPbs2dU6T0pKivvnRo0a6ZprrtHmzZsl/fcOVkREhIYMGeLu16BBA61fv95j+/FdI0nq3LmzxzqmlJQUffvtt6qoqNDmzZsVFBSk5ORk9/7o6GiPa5+6s2TTrl07j8fNmjVTYWFhtcYP4PyxwBtAnRUaGqobb7xRN954ox5++GH9+te/1sSJE7V8+XJJ8lgjVJOX1n685snpdLp/DggI0FVXXVXzws9BWFjYWfvUq1fP47HD4VBlZWVtlQTgDLizBMBvtGnTRkeOHFGTJk0kSXv37nXv+3Hw+bEvvvjC/fOhQ4f0zTffKCEhQZJ01VVXubemTZtWq5ZVq1addp3WrVsrMDBQCQkJOnHihEefAwcOaOvWrWrTpo2kk3eNcnJyqnVNAL7BnSUAdc6BAwf0y1/+Uvfee6/atWunBg0aaO3atZo2bZp69OihsLAwde7cWY899piuuOIKFRYWavz48VWea/LkyYqOjlZMTIzGjRunxo0bq2fPntbrG2OUn59/WnvTpk0VEHDy/2Pu3LlTI0eO1G9+8xutW7dOzzzzjGbMmCFJat26tXr06KH77rtPf/7zn9WgQQONHTtWl112mXr06CFJysrKUmJiou6//34NGTJEwcHBWrZsmX75y1+qcePG5zF7ALyNsASgzomIiFBycrKeeuopfffddyovL1dcXJzuu+8+PfTQQ5KkV155RZmZmerYsaOuueYaTZs2TTfddNNp53rsscf04IMP6ttvv1WHDh30z3/+U8HBwdbrl5SUqFmzZqe17927Vy6XS5I0cOBAHTt2TElJSQoMDNSDDz6owYMHu/u++uqrevDBB3XbbbeprKxMP/vZz7Ro0SL3S2tXX321PvroIz300ENKSkpSWFiYkpOTlZGRUeN5A1A7HObHL/oDAM6qW7du6tChg7Kzs31dCoALgDVLAAAAFoQlAAAAC16GAwAAsODOEgAAgAVhCQAAwIKwBAAAYEFYAgAAsCAsAQAAWBCWAAAALAhLAAAAFoQlAAAAi/8PFXbQ4SxDJc4AAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from torch.utils.data import DataLoader, Dataset, random_split\n",
    "from lib.checkpoint import load_checkpoint, save_checkpoint\n",
    "from lib.image import load_encoded_data\n",
    "from lib.binvox import load_voxel_file\n",
    "from lib.config import *\n",
    "from lib.autoencoder import *\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LSTM_NEUROES = ENCODED_TENSOR_SIZE\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EarlyStopping:\n",
    "    def __init__(self, patience=5, min_delta=0):\n",
    "        self.patience = patience\n",
    "        self.min_delta = min_delta\n",
    "        self.best_loss = None\n",
    "        self.counter = 0\n",
    "\n",
    "    def __call__(self, val_loss):\n",
    "        if self.best_loss is None:\n",
    "            self.best_loss = val_loss\n",
    "            return False\n",
    "\n",
    "        if val_loss < self.best_loss - self.min_delta:\n",
    "            self.best_loss = val_loss\n",
    "            self.counter = 0\n",
    "            return False\n",
    "        else:\n",
    "            self.counter += 1\n",
    "            if self.counter >= self.patience:\n",
    "                return True\n",
    "            return False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTM(nn.Module):\n",
    "    def __init__(self, input_size=LSTM_NEUROES, hidden_size=LSTM_NEUROES, num_layers=2, output_size=LSTM_NEUROES):\n",
    "        super(LSTM, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_size, output_size)\n",
    "        self.input_fc = nn.Linear(input_size + output_size, input_size)  # 映射到 input_size\n",
    "\n",
    "    def forward(self, input_t, prev_output, h_0, c_0):\n",
    "        if prev_output is not None:\n",
    "            input_t = torch.cat((input_t, prev_output), dim=1)\n",
    "            input_t = self.input_fc(input_t)  # 映射到原始input_size\n",
    "\n",
    "        input_t = input_t.unsqueeze(1)  # 调整形状为 (batch_size, seq_len, input_size)\n",
    "        out, (h_0, c_0) = self.lstm(input_t, (h_0, c_0))\n",
    "        out = self.fc(out[:, -1, :])\n",
    "        return out, h_0, c_0\n",
    "        \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CTNN3DDecoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CTNN3DDecoder, self).__init__()\n",
    "        self.fc = nn.Linear(LSTM_NEUROES, 8*8*8*16)  # 假設 LSTM_NEUROES 是可變的\n",
    "        \n",
    "        self.conv1 = nn.ConvTranspose3d(in_channels=16, out_channels=12, kernel_size=3, stride=1, padding=1)\n",
    "        self.relu1 = nn.ReLU()\n",
    "        self.dropout1 = nn.Dropout3d(p=0.2)\n",
    "        self.upsample1 = nn.Upsample(scale_factor=2, mode='nearest')\n",
    "        \n",
    "        self.conv2 = nn.ConvTranspose3d(in_channels=12, out_channels=8, kernel_size=3, stride=1, padding=1)\n",
    "        self.relu2 = nn.ReLU()\n",
    "        self.dropout2 = nn.Dropout3d(p=0.2)\n",
    "        self.upsample2 = nn.Upsample(scale_factor=2, mode='nearest')\n",
    "        \n",
    "        self.conv3 = nn.ConvTranspose3d(in_channels=8, out_channels=4, kernel_size=3, stride=1, padding=1)\n",
    "        self.relu3 = nn.ReLU()\n",
    "        self.dropout3 = nn.Dropout3d(p=0.2)\n",
    "        self.upsample3 = nn.Upsample(scale_factor=2, mode='nearest')\n",
    "        \n",
    "        self.conv4 = nn.ConvTranspose3d(in_channels=4, out_channels=4, kernel_size=3, stride=1, padding=1)\n",
    "        self.relu4 = nn.ReLU()\n",
    "        self.dropout4 = nn.Dropout3d(p=0.2)\n",
    "        self.upsample4 = nn.Upsample(size=(32, 32, 32), mode='nearest')\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = self.fc(x)\n",
    "        out = out.view(1, 16, 8, 8, 8)\n",
    "        \n",
    "        out = self.conv1(out)\n",
    "        out = self.relu1(out)\n",
    "        out = self.dropout1(out)\n",
    "        out = self.upsample1(out)\n",
    "\n",
    "        out = self.conv2(out)\n",
    "        out = self.relu2(out)\n",
    "        out = self.dropout2(out)\n",
    "        out = self.upsample2(out)\n",
    "        \n",
    "        out = self.conv3(out)\n",
    "        out = self.relu3(out)\n",
    "        out = self.dropout3(out)\n",
    "        out = self.upsample3(out)\n",
    "        \n",
    "        out = self.conv4(out)\n",
    "        out = self.relu4(out)\n",
    "        out = self.dropout4(out)\n",
    "        out = self.upsample4(out)\n",
    "        print(out.shape)\n",
    "        return out\n",
    "\n",
    "model = CTNN3DDecoder()\n",
    "test = torch.randn(LSTM_NEUROES)\n",
    "model(test)\n",
    "# # print model in ram size\n",
    "# print('Model size:', sum(p.numel() for p in model.parameters()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTMDecoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(LSTMDecoder, self).__init__()\n",
    "        self.lstm = LSTM()\n",
    "        self.decoder = CTNN3DDecoder()\n",
    "        \n",
    "    def forward(self, x, prev_output, h_0, c_0):\n",
    "        prev_out, h_0, c_0 = self.lstm(x, prev_output, h_0, c_0)\n",
    "        out = self.decoder(prev_out)\n",
    "        return out, prev_out, h_0, c_0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TrainDataset(Dataset):\n",
    "    def __init__(self, datas, voxel):\n",
    "        self.datas = datas\n",
    "        self.voxel = voxel\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.datas)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return self.datas[index], self.voxel[index].astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_sub_epoch(epoch, datas, model, criterion, optimizer, device):\n",
    "    data_len = len(datas)\n",
    "    train_data, val_data = random_split(datas, [int(data_len * 0.8), data_len - int(data_len * 0.8)])\n",
    "    print(\"Epoch:{} Train Size:{} Val Size:{}\".format(epoch, len(train_data), len(val_data)))\n",
    "\n",
    "    train_loader = DataLoader(train_data, batch_size=1, shuffle=True)\n",
    "    val_loader = DataLoader(val_data, batch_size=1, shuffle=True)\n",
    "    train_logs = []\n",
    "    val_logs = []\n",
    "    # move data and model to device\n",
    "    model.to(device)\n",
    "    criterion.to(device)\n",
    "    seq_len = 1\n",
    "    start = time.time()\n",
    "    model.train()\n",
    "    for inputs, targets in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        inputs = inputs.to(device)\n",
    "        targets = targets.to(device)\n",
    "        batch_size = inputs.size(0)\n",
    "        h_0 = torch.zeros(model.lstm.num_layers, batch_size, model.lstm.hidden_size).to(inputs.device)\n",
    "        c_0 = torch.zeros(model.lstm.num_layers, batch_size, model.lstm.hidden_size).to(inputs.device)\n",
    "        prev_output = None\n",
    "\n",
    "        inputs = inputs.view(batch_size, seq_len, -1)\n",
    "        for t in range(seq_len):\n",
    "            input_t = inputs[:, t]\n",
    "            decode_output, prev_output, h_0, c_0 = model(input_t, prev_output, h_0, c_0)\n",
    "        \n",
    "        test_chennal = decode_output[:, 0]\n",
    "        loss = criterion(test_chennal , targets)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_logs.append(loss.item())\n",
    "\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for inputs, targets in val_loader:\n",
    "            inputs = inputs.to(device)\n",
    "            targets = targets.to(device)\n",
    "            batch_size = inputs.size(0)\n",
    "            h_0 = torch.zeros(model.lstm.num_layers, batch_size, model.lstm.hidden_size).to(inputs.device)\n",
    "            c_0 = torch.zeros(model.lstm.num_layers, batch_size, model.lstm.hidden_size).to(inputs.device)\n",
    "            prev_output = None\n",
    "\n",
    "            inputs = inputs.view(batch_size, seq_len, -1)\n",
    "            for t in range(seq_len):\n",
    "                input_t = inputs[:, t]\n",
    "                decode_output, prev_output, h_0, c_0 = model(input_t, prev_output, h_0, c_0)\n",
    "        \n",
    "            test_chennal = decode_output[:, 0]\n",
    "            loss = criterion(test_chennal , targets)\n",
    "            val_logs.append(loss.item())\n",
    "            \n",
    "    end = time.time()\n",
    "\n",
    "    print(\"Epoch:{} Sub Train Time:{:.2f} Train Loss:{:.4f} Val Loss:{:.4f}\".format(epoch, end - start,\n",
    "                                                                                    sum(train_logs) / len(train_logs),\n",
    "                                                                                    sum(val_logs) / len(val_logs)))\n",
    "    return sum(train_logs) / len(train_logs), sum(val_logs) / len(val_logs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_training(file_path, device, checkpoint_path):\n",
    "    model = LSTMDecoder()\n",
    "    criterion = nn.MSELoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.0001)\n",
    "    early_stopping = EarlyStopping(patience=5, min_delta=0.0001)\n",
    "    epoch_losses = []\n",
    "    num_epochs = 20\n",
    "    \n",
    "    start_epoch, epoch_losses, last_folder, train_loss, val_loss = load_checkpoint(checkpoint_path, model, optimizer, device)\n",
    "\n",
    "    model.train()\n",
    "    for epoch in range(start_epoch, num_epochs):\n",
    "        start = time.time()\n",
    "        cnt = 0\n",
    "        train_loss = []\n",
    "        val_loss = []\n",
    "        resume = (last_folder is not None)\n",
    "        skip_cnt = 0\n",
    "        renders = []\n",
    "        voxels = []\n",
    "        for root, dirs, files in os.walk(\"dataset/\"):\n",
    "            folder = root.split(\"/\")[-1]\n",
    "            if(resume):\n",
    "                if(folder == last_folder):\n",
    "                    print(\"Resume from {}, Skip {} Files\".format(folder, skip_cnt))\n",
    "                    resume = False\n",
    "                else:\n",
    "                    skip_cnt += 1\n",
    "                    continue\n",
    "            start_io = time.time()\n",
    "            if(folder == \"\"): continue\n",
    "            print(root) # print current folder\n",
    "            render = load_encoded_data(root)\n",
    "            voxel = load_voxel_file(root + \"/voxel.txt\")\n",
    "            voxel.reshape(32, 32, 32)\n",
    "            if render is None or voxel is None:\n",
    "                continue             \n",
    "            for i in render:\n",
    "                renders.append(i)\n",
    "                voxels.append(voxel)\n",
    "            cnt += 1\n",
    "            if(cnt >= 10):\n",
    "                end_io = time.time()\n",
    "                print(\"IO Time:{:.2f}\".format(end_io-start_io))\n",
    "                dataset = TrainDataset(renders, voxels)\n",
    "                train, val = train_sub_epoch(epoch, dataset, model, criterion, optimizer, device)\n",
    "                train_loss.append(train)\n",
    "                val_loss.append(val)\n",
    "                renders = []\n",
    "                voxels = []\n",
    "                cnt = 0\n",
    "                start_io = time.time()\n",
    "                save_checkpoint({\n",
    "                    'epoch': epoch,\n",
    "                    'state_dict': model.state_dict(),\n",
    "                    'optimizer': optimizer.state_dict(),\n",
    "                    'epoch_losses': epoch_losses,\n",
    "                    'last_file': folder,\n",
    "                    'train_loss': train_loss,\n",
    "                    'val_loss': val_loss,\n",
    "                }, filename = checkpoint_path)\n",
    "        if(cnt > 0):\n",
    "            dataset = TrainDataset(renders, voxels)\n",
    "            train, val = train_sub_epoch(epoch, dataset, model, criterion, optimizer, device)\n",
    "            train_loss.append(train)\n",
    "            val_loss.append(val)\n",
    "            save_checkpoint({\n",
    "                'epoch': epoch,\n",
    "                'state_dict': model.state_dict(),\n",
    "                'optimizer': optimizer.state_dict(),\n",
    "                'epoch_losses': epoch_losses,\n",
    "                'last_file': None,\n",
    "                'train_loss': train_loss,\n",
    "                'val_loss': val_loss,\n",
    "            }, filename = checkpoint_path)\n",
    "        end = time.time()\n",
    "        epoch_train_loss = sum(train_loss)/len(train_loss)\n",
    "        epoch_val_loss = sum(val_loss)/len(val_loss)\n",
    "        epoch_losses.append((epoch_train_loss, epoch_val_loss))\n",
    "        print(\"Epoch:{} Time:{:.2f} Train Loss:{:.4f} Val Loss:{:.4f}\".format(epoch, end-start, epoch_train_loss, epoch_val_loss))\n",
    "        if early_stopping(epoch_val_loss):\n",
    "            print(\"Early Stopping at Epoch:{}\".format(epoch))\n",
    "            break\n",
    "    return model, epoch_losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_lstmdecoder(device, dataset_path = DEFAULT_ENCODED_DATASET_FOLDER, checkpoint_path = DEFAULT_LSTMDECODER_FILE):\n",
    "    model, epoch_losses = run_training(dataset_path, device, checkpoint_path)\n",
    "    model.eval()\n",
    "    torch.save(model.state_dict(), \"model/lstmdecoder.pth\")\n",
    "    torch.save(model.lstm.state_dict(), \"model/lstm.pth\")\n",
    "    torch.save(model.decoder.state_dict(), \"model/ctnn3d.pth\")\n",
    "    return model, epoch_losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model, epoch_losses = train_lstmdecoder(device)\n",
    "    print(epoch_losses)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 初始化模型\n",
    "model = LSTM()\n",
    "batch_size = 1\n",
    "\n",
    "# 初始化隐藏层状态\n",
    "h_0 = torch.zeros(model.num_layers, batch_size, model.hidden_size)\n",
    "c_0 = torch.zeros(model.num_layers, batch_size, model.hidden_size)\n",
    "\n",
    "# 第一次输入\n",
    "input_1 = torch.randn(batch_size, 1, LSTM_NEUROES)  # (batch_size, seq_len, input_size)\n",
    "print(input_1.shape)\n",
    "output, h_n, c_n = model(input_1, None, h_0, c_0)\n",
    "print(\"第一次输出:\", output)\n",
    "\n",
    "# 第二次输入，使用第一次的输出作为一部分输入\n",
    "input_2 = torch.randn(batch_size, 1, LSTM_NEUROES)  # 另外的输入\n",
    "new_input = torch.cat((input_2, output.unsqueeze(1)), dim=2)  # 合并输出作为输入的一部分\n",
    "new_input = model.input_fc(new_input)  # 映射到原始input_size\n",
    "\n",
    "output, h_n, c_n = model(new_input, h_n, c_n)\n",
    "print(\"第二次输出:\", output)\n",
    "\n",
    "# 多次迭代输入进行修正\n",
    "num_iterations = 5\n",
    "for i in range(num_iterations):\n",
    "    input_next = torch.randn(batch_size, 1, LSTM_NEUROES)  # 另外的输入\n",
    "    new_input = torch.cat((input_next, output.unsqueeze(1)), dim=2)  # 合并输出作为输入的一部分\n",
    "    new_input = model.input_fc(new_input)  # 映射到原始input_size\n",
    "\n",
    "    output, h_n, c_n = model(new_input, h_n, c_n)\n",
    "    print(f\"第{i+3}次输出:\", output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "main",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
